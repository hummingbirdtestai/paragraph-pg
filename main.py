from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from datetime import datetime
from supabase_client import call_rpc, supabase
from gpt_utils import chat_with_gpt  # âœ… still needed for chat only
import json

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Initialize FastAPI app
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = FastAPI(title="Paragraph Orchestra API", version="2.0.0")

# âœ… Allow frontend (Expo / Web / React) to call this API
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Helper: Log conversation turn (student + mentor)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def log_conversation(student_id: str, phase_type: str, phase_json: dict,
                     student_msg: str, mentor_msg):
    try:
        if isinstance(mentor_msg, (dict, list)):
            mentor_serialized = json.dumps(mentor_msg)
        elif mentor_msg is None:
            mentor_serialized = "null"
        else:
            mentor_serialized = str(mentor_msg)

        data = {
            "student_id": student_id,
            "phase_type": phase_type,
            "phase_json": phase_json,
            "conversation_log": [{"student": student_msg, "mentor": mentor_serialized}],
            "updated_at": datetime.utcnow().isoformat() + "Z"
        }
        res = supabase.table("student_conversation").insert(data).execute()
        if res.error:
            print("âŒ Error inserting into student_conversation:", res.error)
    except Exception as e:
        print("âš ï¸ Exception during log_conversation:", e)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Helper: Append ChatGPT reply directly (no RPC)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def append_mentor_message(student_id: str, mentor_reply: str):
    try:
        res = supabase.table("student_conversation")\
            .select("conversation_id, conversation_log")\
            .eq("student_id", student_id)\
            .order("updated_at", desc=True)\
            .limit(1)\
            .execute()

        if not res.data:
            print(f"âš ï¸ No active conversation found for student {student_id}")
            return

        convo = res.data[0]
        convo_id = convo["conversation_id"]
        convo_log = convo["conversation_log"] or []

        convo_log.append({
            "role": "assistant",
            "content": mentor_reply,
            "ts": datetime.utcnow().isoformat() + "Z"
        })

        supabase.table("student_conversation")\
            .update({"conversation_log": convo_log})\
            .eq("conversation_id", convo_id)\
            .execute()

    except Exception as e:
        print("âš ï¸ Exception in append_mentor_message:", e)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Master Endpoint â€” handles all actions
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/orchestrate")
async def orchestrate(request: Request):
    payload = await request.json()
    action = payload.get("action")
    student_id = payload.get("student_id")
    message = payload.get("message")

    print(f"ğŸ¬ Action = {action}, Student = {student_id}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ğŸŸ¢ 1ï¸âƒ£ START
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if action == "start":
        rpc_data = call_rpc("start_orchestra", {"p_student_id": student_id})
        if not rpc_data:
            return {"error": "âŒ start_orchestra RPC failed"}

        phase_type = rpc_data.get("phase_type")
        phase_json = rpc_data.get("phase_json")
        mentor_reply = rpc_data.get("mentor_reply")

        log_conversation(student_id, phase_type, phase_json, "SYSTEM: start", mentor_reply)

        return {
            "phase_type": phase_type,
            "phase_json": phase_json,
            "mentor_reply": mentor_reply
        }

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ğŸŸ¡ 2ï¸âƒ£ CHAT â€” CONTEXTUAL (concept or MCQ)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    elif action == "chat":
        rpc_data = call_rpc("append_student_message", {
            "p_student_id": student_id,
            "p_message": message
        })

        if not rpc_data:
            return {"error": "âŒ append_student_message RPC failed"}

        conversation_log = rpc_data.get("conversation_log")

        # ğŸ§  GPT prompt â€” only uses conversation_log, with consistent style_type mapping
        prompt = """
You are a senior NEET-PG mentor with 30 yrs experience.

Input = array of chat objects [{mentor?, student?}].  
Use earlier messages as context; answer only the **last student's question**.

Reply in ONE of 5 mentor styles, matching the appâ€™s rendering types:
1ï¸âƒ£ "summary" â†’ Crisp Clinical Summary (bullet points)
2ï¸âƒ£ "differential" â†’ Differential Table (comparison)
3ï¸âƒ£ "highyield" â†’ High-Yield Fact Sheet (emoji bullets)
4ï¸âƒ£ "algorithm" â†’ Algorithm / Flow Summary (â†’ steps)
5ï¸âƒ£ "reflection" â†’ Mentor Reflection Block (closing summary)

Rules:
â€¢ â‰¤120 words, NEET-PG tone (friendly + exam-focused)
â€¢ Use Unicode markup (**bold**, *italic*, subscripts/superscripts, arrows, emojis) â€” no LaTeX  
â€¢ Output **strict JSON**:

{
  "style_type": "<summary | differential | highyield | algorithm | reflection>",
  "mentor_reply": "<formatted mentor message>"
}

Now generate the mentor's reply.
"""
        mentor_reply = chat_with_gpt(prompt, conversation_log)
        append_mentor_message(student_id, mentor_reply)

        return {
            "mentor_reply": mentor_reply,
            "context_used": True
        }

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ğŸ”µ 3ï¸âƒ£ NEXT â€” advance to next phase
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    elif action == "next":
        rpc_data = call_rpc("next_orchestra", {"p_student_id": student_id})
        if not rpc_data:
            return {"error": "âŒ next_orchestra RPC failed"}

        phase_type = rpc_data.get("phase_type")
        phase_json = rpc_data.get("phase_json")
        mentor_reply = rpc_data.get("mentor_reply")

        log_conversation(student_id, phase_type, phase_json, "SYSTEM: next", mentor_reply)

        return {
            "phase_type": phase_type,
            "phase_json": phase_json,
            "mentor_reply": mentor_reply
        }

    else:
        return {"error": f"Unknown action '{action}'"}


@app.get("/")
def home():
    return {"message": "ğŸ§  Paragraph Orchestra API is running successfully!"}
